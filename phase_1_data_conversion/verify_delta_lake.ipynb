{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "130598da",
   "metadata": {},
   "source": [
    "# ‚úÖ **Delta Lake Table Verification**\n",
    "\n",
    "This notebook verifies that the Delta Lake table was successfully created and contains the expected data from the raw `.h5` files. We initialize a new Spark session, read in the Delta table, and run basic summary checks ‚Äî including the total number of unique files, and the distribution of labeled examples (`good` vs `bad`). These checks confirm that the ingestion phase completed correctly and that the data is ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d0a1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0543e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÅ Start a new Spark session (same Delta config as before)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Delta Lake Summary\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78294444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the Delta Lake\n",
    "DELTA_PATH = \"../data/delta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b102a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the Delta table\n",
    "df = spark.read.format(\"delta\").load(DELTA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cd277fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      " |-- machine_id: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- operation: string (nullable = true)\n",
      " |-- example_no: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n",
      "+------+------+-------+----------+-----+----+---------+----------+-----+\n",
      "|     x|     y|      z|machine_id|month|year|operation|example_no|label|\n",
      "+------+------+-------+----------+-----+----+---------+----------+-----+\n",
      "|1227.0|-407.0| -894.0|       M01|  Feb|2019|     OP00|       004| good|\n",
      "|1079.0| -19.0| -853.0|       M01|  Feb|2019|     OP00|       004| good|\n",
      "|1100.0| 314.0| -860.0|       M01|  Feb|2019|     OP00|       004| good|\n",
      "|1323.0| -68.0|-1056.0|       M01|  Feb|2019|     OP00|       004| good|\n",
      "|1389.0|-491.0|-1139.0|       M01|  Feb|2019|     OP00|       004| good|\n",
      "+------+------+-------+----------+-----+----+---------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preview the schema and sample rows\n",
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b965630b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of files\n",
    "df.select(\"machine_id\", \"month\", \"year\", \"operation\", \"example_no\", \"label\") \\\n",
    "  .distinct() \\\n",
    "  .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab287141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  bad|   70|\n",
      "| good| 1632|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total number of \"good\" and \"bad\" examples\n",
    "df.select(\"machine_id\", \"month\", \"year\", \"operation\", \"example_no\", \"label\") \\\n",
    "  .distinct() \\\n",
    "  .groupBy(\"label\") \\\n",
    "  .count() \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b460cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
